{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocean Biogeochemical Dynamics Lab, Spring 2021\n",
    "Introduction to Python and Jupyter Notebooks by Nancy Williams\n",
    "\n",
    "This code covers importing, cleaning, and plotting data from a single SOCCOM float in the Southern Ocean. \n",
    "\n",
    "SOCCOM website: https://soccom.princeton.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import toolboxes\n",
    "Always start by importing the tools you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "import seaborn as sns # this will change the look of pandas plots, too\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "import seawater\n",
    "import xarray as xr\n",
    "import os\n",
    "%matplotlib inline \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = (15,9)\n",
    "plt.rcParams['font.size'] = 18\n",
    "#plt.rcParams['lines.linewidth'] = 3\n",
    "# this forces matplotlib to print figures out here when you make plots\n",
    "from IPython.display import Image\n",
    "\n",
    "# Press Shift + Enter to \"run\" this cell and move on to the next one \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where you want the figures to be saved\n",
    "output_dir = 'generated/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(url='https://www3.mbari.org/soccom/images/SOOCNMAP.jpg', width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a map of all of the SOCCOM floats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you make a comment!\n",
    "# Always annotate your code so you know what you did and why\n",
    "# I promise you won't remember the details when it comes time to write up the results\n",
    "\n",
    "# Ideally, you are also using some kind of version control like github\n",
    "# version control allows you to track changes in your code, revert back if you need to,\n",
    "# or even branch a piece of code off into two independent versions.\n",
    "# Also great for collaborative projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a new \"cell\" when you transition to a new step in your code. This allows you to run your code in chunks and better troubleshoot where issues might be. Press Option + Enter to add run and an empty cell below this one\n",
    "# Download the SOCCOM float data snapshot\n",
    "This code imports a SOCCOM biogeochemical Argo Float \"snapshot\" dataset from December 2020 for one float at a time. A snapshot means that the data have been archived with a \"doi\" or digital object identifier. It is frozen in time and is citable, which is important for reproducibiity. When using this dataset for science and publication, it will also be important to document the steps you take when cleaning, reformatting, renaming, changing units, and any calculations you do. \n",
    "\n",
    "The SOCCOM floats measure pH and other carbonate system parameters are estimated by combining float-measured pH with an estimate for alkalinity based on empirical relationships and shipboard bottle samples. There are several options for this alkalinity product (LIAR, MLR, and CANYON). Here we will use LIAR (Locally Interpolated Alkalinity Regression of Carter et al. (2018) http://doi.wiley.com/10.1002/lom3.10232). \n",
    "\n",
    "The files are available in both low resolution and high resolution. The core physical sensors (temperature, salinity, and pressure) measure at a higher depth resolution than the BGC sensors. If you choose low-resolution you lose this high resolution physical data. If you choose high resolution you get the full resolution of physical data and the depths which have no BGC data are empty. For the purposes of this notebook, we will use the low-resolution file because it doesn't take up as much space.\n",
    "\n",
    "There are also both raw and QC files available. The QC (quality control) methods are quite mature at this point and so it is best to use the QC'ed data. If you are working on a project that focuses on sensor QC or you wish to do your own QC, then you may need to download the raw dataset.\n",
    "\n",
    "The entire .zip file with all floats can be downloaded here: \n",
    "https://library.ucsd.edu/dc/object/bb94601812 as the \"LIAR Low resolution ODV format.\" I've already downloaded and unzipped that folder in the current working directory for this notebook and it's called `SOCCOM_LoResQC_LIAR_22Dec2020_odvtxt`. Go look at it. What's inside?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset\n",
    "We want to use Pandas' built-in read_csv function to import a single float data file into a pandas data frame called `flt`. Float 9254 is a good example float, but you can pick any float from the snapshot. To pick another float you can go to the SOCCOM web page sensor status table http://soccom.ucsd.edu/floats/SOCCOM_sensor_stats.html and choose a float with lots of good data (i.e., more in the \"#g\" column than the \"#b\" columns for variables you're interested in analyzing. You can sort the columns on that webpage by clicking on the column header by which you wish to sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a float\n",
    "floatnum='9254' \n",
    "# you can change this number to look at a different float and it will update throughout the file\n",
    "# A value in '' is a string type, not a number to be used in calculations.\n",
    "# A string can also contain letters and symbols\n",
    "\n",
    "floatpath='SOCCOM_LoResQC_LIAR_22Dec2020_odvtxt/' # This is the folder where all the float data live\n",
    "floatsuffix='SOOCNQC.TXT' # all of the Southern Ocean floats have the same suffix\n",
    "flt=pd.read_csv(floatpath+floatnum+floatsuffix, error_bad_lines=False) # concatenates or links together strings\n",
    "# There are a bunch of other input options for this read_csv function, and you can see them by\n",
    "# pressing \"tab\" inside the parenthesis following the function name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python doesn't typically spit out the results unless you ask for them.\n",
    "# This is how you look at just the \"head\" the flt dataframe\n",
    "flt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you look at the whole flt dataframe\n",
    "# It's a big dataframe so this will show you just the head and the tail\n",
    "flt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment lines in data files\n",
    "Clearly something is wrong. We didn't get any meaningful data! Why? Because those are comment lines in the top of the data file.  Let's try telling read_cvs what a comment looks like. We see from the file that the comment lines start with '//'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt=pd.read_csv(floatpath+floatnum+floatsuffix, error_bad_lines=False, comment='/')\n",
    "# There are a bunch of other input options for this function, and you can see them by\n",
    "# typing a comma and then pressing \"tab\" from inside the function parentheses\n",
    "# Run this new read_csv function and look at the header of the new flt dataframe\n",
    "# By running this code you overwrite your last flt dataframe\n",
    "flt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delimiters\n",
    "We are getting warmer, we now see a more meaningful header and some data, but what are those \"\\t\"s? Those are tab delimiters or separators. \"CSV\" stands for Comma Separated Values and \"TSV\" stands for Tab Separated Values. The files typically look identical and the delimiters are often invisible when viewed from excel or a text editor (but you should never use excel to edit text files! Excel can change the format when you save and mess up your code). \n",
    "\n",
    "So now we need to tell read_csv what the delimiter is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt=pd.read_csv(floatpath+floatnum+floatsuffix, error_bad_lines=False, \n",
    "                comment='/', delimiter='\\t')\n",
    "# If your line of code is getting long and you're inside a parentheses, simply press \n",
    "# enter in the code to continue your code onto a new line.\n",
    "# Look at the head\n",
    "flt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That looks better, now let's look at the info for the file to see more:\n",
    "flt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting many rows of data, but only four columns. Why? \n",
    "\n",
    "Because the \"comment\" character used in these float data files is two forward slashes \"//\". Unfortunately, Pandas read_csv can only handle one character in the comment field. Because we entered '/' on any line as the comment character, we also lose everything after any '/'. In this case, we lose everything after \"mon\" in the header row and in all data rows. When creating a data file like this .txt file, you should never use your delimiter/separator character anywhere else in your data file. To work around this, we will first open the file and replace all instances of '//' with '#'. (I checked to make sure \"#\" isn't used in the actual data anywhere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file\n",
    "fin = open(floatpath+floatnum+floatsuffix,'rt',encoding='UTF-8')\n",
    "\n",
    "# output file to which we will write the result\n",
    "fout = open('fltrem.txt','wt')\n",
    "\n",
    "# this is a for loop\n",
    "# for each line in the input file\n",
    "for line in fin:\n",
    "    # red and replace the string and write to the output file\n",
    "    fout.write(line.replace('//','#'))\n",
    "# close the files\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN values\n",
    "NaN (Not a Number) values are used to fill in data files where there is either no data or there is bad data. Instead of NaN, SOCCOM used an absurdly small number as their fill value, a number which is not zero but is so small that you would never get the value from a sensor. You could also use an absurdly large number. We want to replace that fill value with NaN, which python is better equipped to handle. If you don't do this, you can mess up your data because you've got a ton of near-zero values in your calculations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt=pd.read_csv('fltrem.txt',delimiter='\\t',comment='#',na_values=-1E10)\n",
    "# Now I've also added a term to tell read_csv what the \"not a number\" value is in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the info for the flt dataframe you have made\n",
    "flt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the head of the data frame\n",
    "flt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates\n",
    "Notice that the date format is in a text string, and we will want it in a number or \"datetime\" format. We can use a pandas function to_datetime to do this conversion and the new variable 'date' is appended to the end of the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt['date']=pd.to_datetime(flt['mon/day/yr']+' '+ flt['hh:mm'])\n",
    "flt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping your data\n",
    "It's always a good idea to map your data and make sure it is where you think it is. Here we will use cartopy (basemap is deprecated).\n",
    "\n",
    "Since we're talking about the Southern Ocean and there are stark fronts, it's good to plot your data in relation to these fronts. The climatological locations of the fronts are available from Orsi et al. (1995) https://www.sciencedirect.com/science/article/pii/096706379500021W. Text files containing the locations of the fronts are located in the \"fronts\" folder.\n",
    "\n",
    "### Where is your float in relation to the fronts of the ACC?\n",
    "The following code imports the longitudes and latitudes of the five fronts. There are some '%' values in the files which creates breaks in the fronts. If we did not keep these breaks, the fronts would plot across continents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stf=pd.read_csv('fronts/stf.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "saf=pd.read_csv('fronts/saf.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "pf=pd.read_csv('fronts/pf.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "saccf=pd.read_csv('fronts/saccf.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "sbdy=pd.read_csv('fronts/sbdy.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "# Check one of the fronts and make sure it looks as you thinkg it should\n",
    "pf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cartopy\n",
    "The following is an example of a South Polar Stereographic map using Cartopy https://scitools.org.uk/cartopy/docs/latest/#. Polar stereographic maps are always a bit more complicated because you have to translate your coordinates to polar coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "ax.set_extent([-180,180,-90,-30],ccrs.PlateCarree())\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.gridlines()\n",
    "\n",
    "# Compute a circle in axes coordinates, which we can use as a boundary\n",
    "# for the map. We can pan/zoom as much as we like - the boundary will be\n",
    "# permanently circular.\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)\n",
    "\n",
    "ax.set_boundary(circle, transform=ax.transAxes)\n",
    "plt.plot(stf['lon'],stf['lat'],color='Red',transform=ccrs.PlateCarree())\n",
    "plt.plot(saf['lon'],saf['lat'],color='Orange',transform=ccrs.PlateCarree())\n",
    "plt.plot(pf['lon'],pf['lat'],color='Yellow',transform=ccrs.PlateCarree())\n",
    "plt.plot(saccf['lon'],saccf['lat'],color='Green',transform=ccrs.PlateCarree())\n",
    "plt.plot(sbdy['lon'],sbdy['lat'],color='Blue',transform=ccrs.PlateCarree())\n",
    "\n",
    "plt.scatter(flt['Lon [°E]'],flt['Lat [°N]'],color='Black',transform=ccrs.PlateCarree(), s=1)\n",
    "plt.savefig(output_dir+'F'+floatnum+'map.png') \n",
    "plt.savefig(output_dir+'F'+floatnum+'map.jpg') # Changing the suffix will change the format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting profiles\n",
    "\n",
    "Now, let's make a quick plot of temperature versus pressure. This method is quick and dirty but doesn't give us much control over the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(flt['Temperature[°C]'],flt['Pressure[dbar]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something funny? \n",
    "# We want to invert the axis and add some labels\n",
    "\n",
    "# Now we will use the object-oriented programming to have more control over the plot\n",
    "fig = plt.figure()\n",
    "# this allows you to create multiple axes\n",
    "axes1= fig.add_axes([0, 0, 1, 1])\n",
    "axes1.plot(flt['Temperature[°C]'],flt['Pressure[dbar]'])\n",
    "axes1.set_title('Float '+floatnum+' Temperature')\n",
    "axes1.invert_yaxis()\n",
    "axes1.set_xlabel('Temperature [°C]')\n",
    "axes1.set_ylabel('Pressure [dbar]')\n",
    "# if you wanted to add a subplot you would add it like this\n",
    "#axes2= fig.add_axes([.7, .7, .2, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also use subplots function\n",
    "fig,axes = plt.subplots(nrows = 1, ncols = 2)\n",
    "# if you have many subplots and some overlap, use tight_layout, or you can leave it \n",
    "# at the end of all of your plot statements\n",
    "# Or you can add bbox_inches='tight' to your print statements\n",
    "\n",
    "axes[0].plot(flt['Temperature[°C]'],flt['Pressure[dbar]'])\n",
    "#axes[0].set_title('Temperature')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_ylabel('Pressure [dbar]')\n",
    "axes[0].set_xlabel('Temperature [°C]')\n",
    "\n",
    "axes[1].plot(flt['Salinity[pss]'],flt['Pressure[dbar]'])\n",
    "#axes[1].set_title('Salinity')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_ylabel('Pressure [dbar]')\n",
    "axes[1].set_xlabel('Salinity [pss]')\n",
    "axes[0].set_title('Float '+floatnum)\n",
    "axes[1].set_title('Float '+floatnum)\n",
    "# This is the first figure we're saving. We have given it a name, a type, and a dpi or\n",
    "# dots per inch which is resolution\n",
    "fig.savefig(output_dir+'F'+floatnum+'TS.png', dpi = 200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's plot multiple things on one axis\n",
    "# Pick your variables:\n",
    "var='DIC_LIAR[µmol/kg]'\n",
    "var2='TALK_LIAR[µmol/kg]'\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "ax.plot(flt[var],flt['Pressure[dbar]'],label = var, color = 'red')\n",
    "ax.plot(flt[var2],flt['Pressure[dbar]'],label = var2, color = 'blue') \n",
    "# for color you can also put in an RGB hex code\n",
    "ax.legend(loc=0) # 0 is for the \"best\" location\n",
    "ax.set_title('Float '+floatnum)# Figure out how to have this be dynamic and change with the float number\n",
    "ax.invert_yaxis()\n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+var2[0:3]+'.png', dpi = 200, bbox_inches='tight')\n",
    "flt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Flags\n",
    "Clearly there are some bad data. Notice the QF or Quality Flag columns in the flt dataframe. These tell us which data are good, questionable, and bad. We only want to use good data. How can we tell which data are good?\n",
    "\n",
    "Go back to the original text file and read the comments at the top of the file. Good data are flagged with zeros, and we should remove bad and questionable data which are flagged 4 and 3, respectively, and replace with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all QF columns and apply them to the preceeding columns\n",
    "from re import search\n",
    "for column in range(len(flt.columns)):\n",
    "    name=flt.columns[column]\n",
    "    if search('QF',name): # if the column is a QF column, apply it to the preceeding column, otherwise go on to next column\n",
    "        var=flt.columns[column-1]\n",
    "        flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now make the same plot again and see if the weird data are gone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var='DIC_LIAR[µmol/kg]'\n",
    "var2='TALK_LIAR[µmol/kg]'\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "ax.plot(flt[var],flt['Pressure[dbar]'],label = var, color = 'red')\n",
    "ax.plot(flt[var2],flt['Pressure[dbar]'],label = var2, color = 'blue') \n",
    "# for color you can also put in an RGB hex code\n",
    "ax.legend(loc=0) # 0 is for the \"best\" location\n",
    "ax.set_title('Float '+floatnum)# Figure out how to have this be dynamic and change with the float number\n",
    "ax.invert_yaxis()\n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+var2[0:3]+'.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, they are!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note: Careful, if you are using the High-Resolution dataset and you use \"plot\" for BGC variables you will get a HUGE gap in the mid-water column because the BGC data are not high resolution. We need to use 'scatter' for the BGC data in the High-Resolution dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var='pHinsitu[Total]'\n",
    "fig = plt.figure()\n",
    "axes1= fig.add_axes([0.1, 0.1, .8, .8])\n",
    "axes1.plot(flt[var],flt['Pressure[dbar]'],label = var,color='purple')\n",
    "axes1.legend()\n",
    "axes1.set_title('Float '+floatnum)\n",
    "axes1.invert_yaxis()\n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+'.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is nitrate there?\n",
    "var='Nitrate[µmol/kg]'\n",
    "fig = plt.figure()\n",
    "axes1= fig.add_axes([0.1, 0.1, .8, .8])\n",
    "axes1.plot(flt[var],flt['Pressure[dbar]'],label = var,color='green')\n",
    "axes1.legend()\n",
    "axes1.set_title('Float '+floatnum)\n",
    "axes1.invert_yaxis()\n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+'QC.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is oxygen there?\n",
    "var='Oxygen[µmol/kg]'\n",
    "fig = plt.figure()\n",
    "axes1= fig.add_axes([0.1, 0.1, .8, .8])\n",
    "axes1.plot(flt[var],flt['Pressure[dbar]'],label = var,color='teal')\n",
    "axes1.legend()\n",
    "axes1.set_title('Float '+floatnum)\n",
    "axes1.invert_yaxis()\n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+'QC.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next look at oxygen over time\n",
    "var='Oxygen[µmol/kg]'\n",
    "fig = plt.figure(num=None, figsize=(16, 3), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc=ax.scatter(flt['date'],flt['Depth[m]'],c=flt[var],cmap = 'magma')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Float '+floatnum)\n",
    "cb=plt.colorbar(sc)\n",
    "cb.set_label(var)\n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+'section.png', dpi = 200,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Layer Depth\n",
    "It would be helpful to know where the mixed layer is when we're thinking about surface ocean seasonality. Typically, mixed layer is calculated by looking at the density relative to the surface. As you move down the water column, the density increases and you can choose a threshold above which you are no longer in the mixed layer. This is typically 0.03 kg/m3 (https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2004JC002378). First let's look at density. Sigma theta is actually the density minus 1000 kg/m3. The true density is closer to 1027 kg/m3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt['Sigma_theta[kg/m^3]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with station 1 as a test. Find the surface density (usually the minimum, but not always- fix later)\n",
    "station=1\n",
    "surfacedens=flt['Sigma_theta[kg/m^3]'].loc[(flt['Station']==station)].min()\n",
    "surfacedens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find where in that station the density is greater than 0.03 greater than the surface density\n",
    "# the shallowest of those depths is the mixed layer depth\n",
    "MLD=flt['Depth[m]'].loc[(flt['Station']==station)&(flt['Sigma_theta[kg/m^3]']-surfacedens>0.03)].min()\n",
    "MLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MLD for each station\n",
    "MLD=[]\n",
    "for station in flt['Station'].unique():\n",
    "    surfacedens=flt['Sigma_theta[kg/m^3]'].loc[(flt['Station']==station)].min()\n",
    "    MLD.append([station,flt['date'].loc[(flt['Station']==station)&(flt['Sigma_theta[kg/m^3]']-surfacedens>0.03)].min(),\n",
    "                flt['Depth[m]'].loc[(flt['Station']==station)&(flt['Sigma_theta[kg/m^3]']-surfacedens>0.03)].min(),\n",
    "              flt['Lon [°E]'].loc[(flt['Station']==station)].mean(),\n",
    "              flt['Lat [°N]'].loc[(flt['Station']==station)].mean()])\n",
    "\n",
    "# Take a look at MLD. First column is the Station, second column is datenum, second column is the MLD\n",
    "MLD = pd.DataFrame(data=MLD, columns=['Station', 'date', 'MLD','Lon [°E]','Lat [°N]'])\n",
    "print(MLD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Density in the mixed layer\n",
    "# First, set the depth to which you wish to plot and keep it the same for subsequent plots\n",
    "depth=MLD['MLD'].max()+50 #plot to depth of mixed layer plus some number of m\n",
    "\n",
    "var='Sigma_theta[kg/m^3]'\n",
    "flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)\n",
    "fig = plt.figure(num=None, figsize=(16,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc=ax.scatter(flt['date'],flt['Depth[m]'],c=flt[var],cmap = 'Reds')\n",
    "ax.plot(MLD['date'],MLD['MLD'],c='magenta')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Float '+floatnum)\n",
    "ax.set_ylim([depth,0])\n",
    "cb=plt.colorbar(sc)\n",
    "cb.set_label(var)\n",
    "# automatically adjusts the colorbar based on the range of values youre plotting\n",
    "sc.set_clim(vmin = flt[var].loc[(flt['Depth[m]']<depth)].min(), \n",
    "            vmax = flt[var].loc[(flt['Depth[m]']<depth)].max()) \n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+'section.png', dpi = 200,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed layer climatology\n",
    "The Holte and Talley climatology for mixed layer depth is informed by Argo profiles and it lives at http://mixedlayer.ucsd.edu/. It would be interesting to see how the mixed layer we calculated/observed from the float compares to the climatological mixed layer depth near the float location. This code section is adapted from Ryan Abernathy's Intro to Physical Oceanography notebook at https://nbviewer.jupyter.org/github/rabernat/intro_to_physical_oceanography/blob/master/lectures/03_air_sea_exchange.ipynb.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"generated\") # Change the directory to the `generated` folder\n",
    "os.getcwd() # Check that you're now in the `generated` folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Curl downloads the mixed layer depths file directly from the web and shows you the status while it works. \n",
    "# `!` at the beginning of the line tells you that this command is a unix shell command (not python code)\n",
    "! curl -o Argo_mixedlayers_monthlyclim_12112019.nc http://mixedlayer.ucsd.edu/data/Argo_mixedlayers_monthlyclim_12112019.nc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using xarray to open the MLD dataset\n",
    "MLDclim = xr.open_dataset('Argo_mixedlayers_monthlyclim_12112019.nc')\n",
    "os.chdir(\"..\") # Use \"..\" to move back up one directory now that we've imported the MLD climatology data\n",
    "MLDclim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# July\n",
    "fig, ax = plt.subplots()\n",
    "im = MLDclim.mld_da_mean[:,:,6].plot.imshow(extent=[MLDclim.lon[0], MLDclim.lon[-1],\n",
    "                                                    MLDclim.lat[-1], MLDclim.lat[0]], yincrease=True)\n",
    "im.set_clim([0,500])\n",
    "ax.set_title('July Climatological MLD from Holte et al. (2007)')\n",
    "plt.savefig(output_dir+'JulyClimatologicalMLD.png', dpi = 200,bbox_inches='tight')\n",
    "plt.close()\n",
    "fig\n",
    "# Clean up the axes later. these are the indices, not the lats and lons themselves"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at biogeochemical section plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next look at pCO2 over time\n",
    "var='pCO2_LIAR[µatm]'\n",
    "flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)\n",
    "fig = plt.figure(num=None, figsize=(16,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc=ax.scatter(flt['date'],flt['Depth[m]'],c=flt[var],cmap = 'Reds')\n",
    "ax.plot(MLD['date'],MLD['MLD'],c='magenta')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Float '+floatnum)\n",
    "ax.set_ylim([depth,0])\n",
    "cb=plt.colorbar(sc)\n",
    "cb.set_label(var)\n",
    "# automatically adjusts the colorbar based on the range of values youre plotting\n",
    "sc.set_clim(vmin = flt[var].loc[(flt['Depth[m]']<depth)].min(), \n",
    "            vmax = flt[var].loc[(flt['Depth[m]']<depth)].max()) \n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+'section.png', dpi = 200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next look at Nitrate over time\n",
    "var='Nitrate[µmol/kg]'\n",
    "fig = plt.figure(num=None, figsize=(16,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc=ax.scatter(flt['date'],flt['Depth[m]'],c=flt[var],cmap = 'Purples')\n",
    "ax.plot(MLD['date'],MLD['MLD'],c='magenta')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Float '+floatnum)\n",
    "ax.set_ylim([depth,0])\n",
    "cb=plt.colorbar(sc)\n",
    "cb.set_label(var)\n",
    "# automatically adjusts the colorbar based on the range of values youre plotting\n",
    "sc.set_clim(vmin = flt[var].loc[(flt['Depth[m]']<depth)].min(), \n",
    "            vmax = flt[var].loc[(flt['Depth[m]']<depth)].max()) \n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+'section.png', dpi = 200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next look at Chlorophyll over time \n",
    "var='Chl_a_corr[mg/m^3]'\n",
    "fig = plt.figure(num=None, figsize=(16,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc=ax.scatter(flt['date'],flt['Depth[m]'],c=np.log(flt[var]),cmap = 'Greens') #Log scale\n",
    "ax.plot(MLD['date'],MLD['MLD'],c='magenta')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Float '+floatnum)\n",
    "ax.set_ylim([depth,0])\n",
    "cb=plt.colorbar(sc)\n",
    "cb.set_label('log('+var+')')\n",
    "fig.savefig(output_dir+'F'+floatnum+var[0:3]+'section.png', dpi = 200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a time series plot of average top 30 m observations\n",
    "Here we use the pandas groupby function to group the near-surface data by station.\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to work on this loop to use actual MLD instead of 30 m for averaging\n",
    "#fltSurf=pd.DataFrame()\n",
    "#for station in MLD['Station'].unique():\n",
    "#    stationMLD=MLD['MLD'].loc[(MLD['Station']==station)]\n",
    "#    mask=flt.loc[(flt['Station']==station),(flt['Pressure[dbar]']<stationMLD)]\n",
    "#    fltSurf=fltSurf.append(flt[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltSurf=flt.loc[(flt['Pressure[dbar]']<30)]\n",
    "fltSurfByStn=fltSurf.groupby('Station').mean()\n",
    "fltSurfByStn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby doesn't work on datetime column so it was dropped. We need to make a datetime array to be used with plotting\n",
    "fltdates=[]\n",
    "for station in flt['Station'].unique():\n",
    "    fltdates.append([flt['date'].loc[(flt['Station']==station)].min()])\n",
    "len(fltdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, sometimes the fltdates is 1 row longer than the groupby file. \n",
    "# Not sure how/why this happened but for now, we will just assume that \n",
    "# there is an extra date somewhere and drop the final date.\n",
    "# Need to fix this later. It might lead to a 10-day error in the dates\n",
    "if len(fltdates)>len(fltSurfByStn):\n",
    "    fltdates.pop()# pop \"pops off\" the last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a big plot with subplots\n",
    "fig,axes = plt.subplots(nrows = 7, ncols = 1,figsize=(15,25))\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "var='Temperature[°C]'\n",
    "axes[0].plot(fltdates,fltSurfByStn[var])\n",
    "axes[0].set_ylabel(var)\n",
    "axes[0].set_xlim(fltdates[0],fltdates[-1])\n",
    "# format the ticks\n",
    "axes[0].xaxis.set_major_locator(years)\n",
    "axes[0].xaxis.set_major_formatter(years_fmt)\n",
    "axes[0].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='Salinity[pss]'\n",
    "axes[1].plot(fltdates,fltSurfByStn[var])\n",
    "axes[1].set_ylabel(var)\n",
    "axes[1].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[1].xaxis.set_major_locator(years)\n",
    "axes[1].xaxis.set_major_formatter(years_fmt)\n",
    "axes[1].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='Chl_a_corr[mg/m^3]'\n",
    "axes[2].plot(fltdates,np.log(fltSurfByStn[var]))\n",
    "axes[2].set_ylabel('log('+var+')')\n",
    "axes[2].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[2].xaxis.set_major_locator(years)\n",
    "axes[2].xaxis.set_major_formatter(years_fmt)\n",
    "axes[2].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='OxygenSat[%]'\n",
    "axes[3].plot(fltdates,fltSurfByStn[var])\n",
    "axes[3].set_ylabel(var)\n",
    "axes[3].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[3].xaxis.set_major_locator(years)\n",
    "axes[3].xaxis.set_major_formatter(years_fmt)\n",
    "axes[3].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='Nitrate[µmol/kg]'\n",
    "axes[4].plot(fltdates,fltSurfByStn[var])\n",
    "axes[4].set_ylabel(var)\n",
    "axes[4].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[4].xaxis.set_major_locator(years)\n",
    "axes[4].xaxis.set_major_formatter(years_fmt)\n",
    "axes[4].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='pCO2_LIAR[µatm]'\n",
    "axes[5].plot(fltdates,fltSurfByStn[var])\n",
    "axes[5].set_ylabel(var)\n",
    "axes[5].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[5].xaxis.set_major_locator(years)\n",
    "axes[5].xaxis.set_major_formatter(years_fmt)\n",
    "axes[5].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='MLD'\n",
    "axes[6].plot(MLD['date'],MLD['MLD'])\n",
    "axes[6].set_ylabel(var)\n",
    "axes[6].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[6].xaxis.set_major_locator(years)\n",
    "axes[6].xaxis.set_major_formatter(years_fmt)\n",
    "axes[6].xaxis.set_minor_locator(months)\n",
    "\n",
    "axes[0].set_title('Float '+floatnum)\n",
    "# This is the first figure we're saving. We have given it a name, a type, and a dpi or\n",
    "# dots per inch which is resolution\n",
    "fig.savefig(output_dir+'F'+floatnum+'TS.png', dpi = 200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seawater Toolbox\n",
    "The seawater toolbox contains many functions useful for oceanographic data analysis. To see a list of what's there type `help(seawater)`. Let's calculate the freezing point of seawater over the float's lifetime. You could also calculate the oxygen saturation concentration. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seawater.fp(fltSurfByStn['Salinity[pss]'],fltSurfByStn['Pressure[dbar]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other miscellaneous plotting tools\n",
    "In the following section I will demonstrate a few other neat plotting tools from the Seaborn toolbox: https://seaborn.pydata.org/#. \n",
    "\n",
    "For *this* specific dataset, using Seaborn doesn't always give us something oceanographically meaningful, but I want you to know that they exist.\n",
    "\n",
    "The first example is using distplot: https://seaborn.pydata.org/generated/seaborn.distplot.html?highlight=distplot#seaborn.distplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var='Temperature[°C]'\n",
    "var='Salinity[pss]'\n",
    "\n",
    "sns.distplot(fltSurfByStn['Temperature[°C]'],kde='false')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next couple of examples uses a jointplot: https://seaborn.pydata.org/generated/seaborn.jointplot.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='Temperature[°C]',y='Salinity[pss]',data=fltSurfByStn,kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='Temperature[°C]',y='Salinity[pss]',data=fltSurfByStn,kind='reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next example wants to plot an entire dataframe. Our flt dataframe is too big, so I'm making a smaller dataframe called fltsmall with just the variables we want to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltSurfByStnsmall=fltSurfByStn[['Chl_a_corr[mg/m^3]','Nitrate[µmol/kg]','Oxygen[µmol/kg]','pCO2_LIAR[µatm]','Temperature[°C]','Depth[m]']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltSurfByStnsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(fltSurfByStnsmall)\n",
    "# This will take some time. Notice the \"*\" that appears to the upper left while the cell runs\n",
    "# If something is taking longer to run than you think it should, that's called \"hanging\" and\n",
    "# It may be due to an error. You can quit that cell by going up to \"Kernel\" in the menu bar and \n",
    "# clicking \"interrupt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also use the following code to make a pivot table with a subsample of the larger dataframe \n",
    "# to be used with seaborn grid plots\n",
    "# a=flt.pivot_table(index='Pressure[dbar]',columns='Station',values='Temperature[°C]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression plot\n",
    "https://seaborn.pydata.org/generated/seaborn.lmplot.htmls\n",
    "\n",
    "What is the relationship between TALK and S? Do you think that Alkalinity can be estimated from just salinity?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='Salinity[pss]',y='TALK_LIAR[µmol/kg]',data=fltSurfByStn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about dissolved inorganic carbon (DIC)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='Salinity[pss]',y='DIC_LIAR[µmol/kg]',data=fltSurfByStn) #Seaborn linear model plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are these two different blobs? Plot a third variable as a color\n",
    "fltSurfByStn.plot.scatter(x='Salinity[pss]',y='DIC_LIAR[µmol/kg]',c=fltSurfByStn['Temperature[°C]'],cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
