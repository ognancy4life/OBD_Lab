{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocean Biogeochemical Dynamics Lab, Spring 2021\n",
    "Introduction to Python and Jupyter Notebooks by Nancy Williams\n",
    "\n",
    "Importing and cleaning SOCCOM float data for a single float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you make a comment!\n",
    "# Always annotate your code so you know what you did and why\n",
    "# I promise you won't remember the details when it comes time to write up the results\n",
    "\n",
    "# Ideally, you are also using some kind of version control like github\n",
    "# version control allows you to track changes in your code, revert back if you need to,\n",
    "# or even branch a piece of code off into two independent versions.\n",
    "# Also great for collaborative projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import toolboxes\n",
    "Always start by importing the tools you will need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "import seaborn as sns # this will change the look of pandas plots too\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "import seawater\n",
    "%matplotlib inline \n",
    "# this forces matplotlib to print figures out here when you make plots\n",
    "\n",
    "# Press Shift + Enter to \"run\" this cell and move on to the next one\n",
    "# Press Option + Enter to add run and an empty cell below this one "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start a new \"cell\" when you transition to a new step in your code. This allows you to run your code in chunks and better troubleshoot where issues might be.\n",
    "# Download the SOCCOM float data snapshot\n",
    "This code imports a SOCCOM biogeochemical Argo Float \"snapshot\" dataset from December 2020 for one float. A snapshot means that the data have been archived with a \"doi\" or digital object identifier. It is frozen in time and is citable, whic is important for reproducibiity. When using this dataset for science, it will also be important to document the steps you take when cleaning, reformatting, renaming, changing units, and any calculations you do. \n",
    "\n",
    "The entire .zip file with all floats can be downloaded here: \n",
    "https://library.ucsd.edu/dc/object/bb94601812 as the \"LIAR High resolution ODV format\"\n",
    "\n",
    "The SOCCOM floats measure pH and other carbonate system parameters are estimated by combining float-measured pH with an estimate for alkalinity based on empirical relationships and shipboard bottle samples. There are several options for this alkalinity product (LIAR, MLR, and CANYON). Here we will use LIAR (Locally Interpolated Alkalinity Regression of Carter et al. (2018) http://doi.wiley.com/10.1002/lom3.10232). \n",
    "\n",
    "The files are also available in low resolution and high resolution. The core physical sensors (temperature, salinity, and pressure) measure at a higher depth resolution than the BGC sensors. If you choose low-resolution you lose this high resolution physical data. If you choose high resolution you get the full resolution of physical data and the depths which have no BGC data are empty.\n",
    "\n",
    "There are both raw and QC files available. The QC (quality control) methods are quite mature at this point and so it is best to use the QC'ed data. If you are working on a project that focuses on sensor QC or you wish to do your own QC, then you may need to download the raw dataset.\n",
    "\n",
    "It is easiest to place the file in the same directory where you will keep this code. Go download, and then go and unzip that file. What's inside?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset\n",
    "We want to use Pandas' built-in read_csv function to import a single float data file into a pandas data frame called \"flt\". Float 9254 is a good example float, but you can pick any float from the snapshot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a float\"\n",
    "floatnum='9254' #you can change this number to look at a different float\n",
    "\n",
    "floatpath='SOCCOM_HiResQC_LIAR_22Dec2020_odvtxt/'\n",
    "floatsuffix='SOOCN_HRQC.TXT'\n",
    "flt=pd.read_csv(floatpath+floatnum+floatsuffix, error_bad_lines=False)\n",
    "# There are a bunch of other input options for this function, and you can see them by\n",
    "# pressing \"tab\" inside the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python doesn't typically spit out the results unless you ask for them.\n",
    "# This is how you look at just the \"head\" the flt dataframe\n",
    "flt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is how you look at the whole flt dataframe\n",
    "flt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments\n",
    "Clearly something is wrong. We didn't get any meaningful data! Why? Because those are comment lines in the top of the data file.  Let's try telling read_cvs what a comment looks like. We see from the file that the comment lines start with '//'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt=pd.read_csv(floatpath+floatnum+floatsuffix, error_bad_lines=False, comment='/')\n",
    "# There are a bunch of other input options for this function, and you can see them by\n",
    "# typing a comma and then pressing \"tab\" from inside the function parentheses\n",
    "# Run this new read_csv function and look at the header of the new flt dataframe\n",
    "# By running this code you overwrite your last flt dataframe\n",
    "flt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delimiters\n",
    "We are getting warmer, we now see a more meaningful header and some data, but what are those \"\\t\"s? Those are tab delimiters/separators. CSV means comma separated values and TSV means tab separated values. The files typically look identical and the tab delimiters are invisible when viewed from excel or a text editor (but you should never use excel to edit text files!). So now we need to tell read_csv what the delimiter is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt=pd.read_csv(floatpath+floatnum+floatsuffix, error_bad_lines=False, \n",
    "                comment='/', delimiter='\\t')\n",
    "# If your line of code is getting long and you're inside a parentheses, simply press \n",
    "# enter in the code to continue your code onto a new line\n",
    "# Look at the header\n",
    "flt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# That looks better, now let's look at the info for the file to see more:\n",
    "flt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are getting many rows of data, but only four columns. Why? \n",
    "\n",
    "Because the \"comment\" character used in these float data files is two forward slashes \"//\". Unfortunately, Pandas read_csv can only handle one character in the comment field. Because we entered '/' as the comment character, we also lose everything after any '/'. In this case, we lose everything after \"mon\" in the header row and in all data rows. When creating a data file like this .txt file, you should never use your delimiter/separator character anywhere else in your data file. To work around this, we will first open the file and replace all instances of '//' with '#'. (I checked to make sure \"#\" isn't used in the actual data anywhere)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input file\n",
    "fin = open(floatpath+floatnum+floatsuffix,'rt',encoding='UTF-8')\n",
    "\n",
    "# output file to which we will write the result\n",
    "fout = open('fltrem.txt','wt')\n",
    "\n",
    "# this is a for loop\n",
    "# for each line in the input file\n",
    "for line in fin:\n",
    "    # red and replace the string and write to the output file\n",
    "    fout.write(line.replace('//','#'))\n",
    "# close the files\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaN values\n",
    "NAN (Not A Number) values are used to fill in where there is either no data or sometimes bad data which has been removed. SOCCOM used an absurdly small number which is not zero, but is so small that you would never get the value from a sensor. You could also use an absurdly large number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt=pd.read_csv('fltrem.txt',delimiter='\\t',comment='#',na_values=-1E10)\n",
    "# Now I've also added a term to tell read_csv what the \"not a number\" value is in the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a look at the info for the flt dataframe you have made\n",
    "flt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the head of the data frame\n",
    "flt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dates\n",
    "Notice that the date format is in a text string, and we will want it in a number or \"datetime\" format. We can use a pandas function to_datetime to do this conversion and the new variable 'date' is appended to the end of the pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt['date']=pd.to_datetime(flt['mon/day/yr']+' '+ flt['hh:mm'])\n",
    "flt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping your data\n",
    "It's always a good idea to map your data and make sure it is where you think it is. Here we will use cartopy (basemap is deprecated).\n",
    "\n",
    "Since we're talking about the Southern Ocean and there are stark fronts, it's good to plot your data in relation to these fronts. The climatological locations of the fronts are available from Orsi et al. (1995) https://www.sciencedirect.com/science/article/pii/096706379500021W. Text files containing the locations of the fronts are located in the \"fronts\" folder.\n",
    "\n",
    "### Where is your float in relation to the fronts of the ACC?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stf=pd.read_csv('fronts/stf.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "saf=pd.read_csv('fronts/saf.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "pf=pd.read_csv('fronts/pf.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "saccf=pd.read_csv('fronts/saccf.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "sbdy=pd.read_csv('fronts/sbdy.txt',header=None,sep='\\s+',na_values='%', names=['lon','lat'])\n",
    "pf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 6))\n",
    "ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "ax.set_extent([-180,180,-90,-30],ccrs.PlateCarree())\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.gridlines()\n",
    "\n",
    "# Compute a circle in axes coordinates, which we can use as a boundary\n",
    "# for the map. We can pan/zoom as much as we like - the boundary will be\n",
    "# permanently circular.\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)\n",
    "\n",
    "ax.set_boundary(circle, transform=ax.transAxes)\n",
    "plt.plot(stf['lon'],stf['lat'],color='Red',transform=ccrs.PlateCarree())\n",
    "plt.plot(saf['lon'],saf['lat'],color='Orange',transform=ccrs.PlateCarree())\n",
    "plt.plot(pf['lon'],pf['lat'],color='Yellow',transform=ccrs.PlateCarree())\n",
    "plt.plot(saccf['lon'],saccf['lat'],color='Green',transform=ccrs.PlateCarree())\n",
    "plt.plot(sbdy['lon'],sbdy['lat'],color='Blue',transform=ccrs.PlateCarree())\n",
    "\n",
    "plt.plot(flt['Lon [°E]'],flt['Lat [°N]'],color='Black',transform=ccrs.PlateCarree())\n",
    "plt.savefig('SPstereo.pdf')\n",
    "plt.savefig('SPstereo.png') # Changing the suffix will change the format\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting profiles\n",
    "\n",
    "Now, let's make a quick plot of temperature versus pressure. This method is quick and dirty but doesn't give us much control over the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(flt['Temperature[°C]'],flt['Pressure[dbar]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something funny? \n",
    "# We want to invert the axis and add some labels\n",
    "\n",
    "# Now we will use the object-oriented programming to have more control over the plot\n",
    "fig = plt.figure()\n",
    "# this allows you to create multiple axes\n",
    "axes1= fig.add_axes([0, 0, 1, 1])\n",
    "axes1.plot(flt['Temperature[°C]'],flt['Pressure[dbar]'])\n",
    "axes1.set_title('Float '+floatnum+' Temperature')\n",
    "axes1.invert_yaxis()\n",
    "axes1.set_xlabel('Temperature [°C]')\n",
    "axes1.set_ylabel('Pressure [dbar]')\n",
    "# if you wanted to add a subplot you would add it like this\n",
    "#axes2= fig.add_axes([.7, .7, .2, .2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can also use subplots function\n",
    "fig,axes = plt.subplots(nrows = 1, ncols = 2,figsize=(6,6))\n",
    "# if you have many subplots and some overlap, use tight_layout, or you can leave it \n",
    "# at the end of all of your plot statements\n",
    "# plt.tight_layout()\n",
    "\n",
    "axes[0].plot(flt['Temperature[°C]'],flt['Pressure[dbar]'])\n",
    "#axes[0].set_title('Temperature')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_ylabel('Pressure [dbar]')\n",
    "axes[0].set_xlabel('Temperature [°C]')\n",
    "\n",
    "axes[1].plot(flt['Salinity[pss]'],flt['Pressure[dbar]'])\n",
    "#axes[1].set_title('Salinity')\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_ylabel('Pressure [dbar]')\n",
    "axes[1].set_xlabel('Salinity [pss]')\n",
    "axes[0].set_title('Float '+floatnum)\n",
    "axes[1].set_title('Float '+floatnum)\n",
    "plt.tight_layout()\n",
    "# This is the first figure we're saving. We have given it a name, a type, and a dpi or\n",
    "# dots per inch which is resolution\n",
    "fig.savefig('F'+floatnum+'TS.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's plot multiple things on one axis\n",
    "# Pick your variables:\n",
    "var='DIC_LIAR[µmol/kg]'\n",
    "var2='TALK_LIAR[µmol/kg]'\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "ax.scatter(flt[var],flt['Pressure[dbar]'],label = var, color = 'red')\n",
    "ax.scatter(flt[var2],flt['Pressure[dbar]'],label = var2, color = 'blue') \n",
    "# for color you can also put in an RGB hex code\n",
    "ax.legend(loc=0) # 0 is for the \"best\" location\n",
    "ax.set_title('Float '+floatnum)# Figure out how to have this be dynamic and change with the float number\n",
    "ax.invert_yaxis()\n",
    "fig.savefig('F'+floatnum+var[0:3]+var2[0:3]+'.png', dpi = 200)\n",
    "flt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Flags\n",
    "Clearly there are some bad data. Notice the QF or Quality Flag columns in the flt dataframe. These tell us which data are good, questionable, and bad. We only want to use good data. How can we tell which data are good?\n",
    "\n",
    "Go back to the original text file and read the comments at the top of the file. Good data are flagged with zeros, and we should remove bad and questionable data which are flagged 4 and 3, respectively, and replace with NaN. There are better ways to automate this, but for now we will do it manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is where we left off in class on Jan 22\n",
    "# Plotting DIC and total alkalinity\n",
    "var='DIC_LIAR[µmol/kg]'\n",
    "var2='TALK_LIAR[µmol/kg]'\n",
    "flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)\n",
    "\n",
    "# Now replot that same figure\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "ax.scatter(flt[var],flt['Pressure[dbar]'],label = var, color = 'red')\n",
    "ax.scatter(flt[var2],flt['Pressure[dbar]'],label = var2, color = 'blue') \n",
    "# for color you can also put in an RGB hex code\n",
    "ax.legend(loc=0) # 0 is for the \"best\" location\n",
    "ax.set_title('Float '+floatnum)\n",
    "ax.invert_yaxis()\n",
    "fig.savefig('F'+floatnum+var[0:3]+var2[0:3]+'.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful, if you use \"plot\" we get a HUGE gap in the mid-water column because the BGC data are not high resolution. We need to use 'scatter' for the BGC data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var='pHinsitu[Total]'\n",
    "\n",
    "fig = plt.figure()\n",
    "axes1= fig.add_axes([0.1, 0.1, .8, .8])\n",
    "axes1.scatter(flt[var],flt['Pressure[dbar]'],label = var,color='purple')\n",
    "axes1.legend()\n",
    "axes1.set_title('Float '+floatnum)\n",
    "axes1.invert_yaxis()\n",
    "fig.savefig('F'+floatnum+var[0:3]+'.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var='pHinsitu[Total]'\n",
    "flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)\n",
    "fig = plt.figure()\n",
    "axes1= fig.add_axes([0.1, 0.1, .8, .8])\n",
    "axes1.scatter(flt[var],flt['Pressure[dbar]'],label = var,color='purple')\n",
    "axes1.legend()\n",
    "axes1.set_title('Float '+floatnum)\n",
    "axes1.invert_yaxis()\n",
    "fig.savefig('F'+floatnum+var[0:3]+'QC.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is nitrate there?\n",
    "var='Nitrate[µmol/kg]'\n",
    "flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)\n",
    "fig = plt.figure()\n",
    "axes1= fig.add_axes([0.1, 0.1, .8, .8])\n",
    "axes1.scatter(flt[var],flt['Pressure[dbar]'],label = var,color='green')\n",
    "axes1.legend()\n",
    "axes1.set_title('Float '+floatnum)\n",
    "axes1.invert_yaxis()\n",
    "fig.savefig('F'+floatnum+var[0:3]+'QC.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is oxygen there?\n",
    "var='Oxygen[µmol/kg]'\n",
    "flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)\n",
    "fig = plt.figure()\n",
    "axes1= fig.add_axes([0.1, 0.1, .8, .8])\n",
    "axes1.scatter(flt[var],flt['Pressure[dbar]'],label = var,color='teal')\n",
    "axes1.legend()\n",
    "axes1.set_title('Float '+floatnum)\n",
    "axes1.invert_yaxis()\n",
    "fig.savefig('F'+floatnum+var[0:3]+'QC.png', dpi = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next look at oxygen over time\n",
    "var='Oxygen[µmol/kg]'\n",
    "fig = plt.figure(num=None, figsize=(10, 2), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc=ax.scatter(flt['date'],flt['Depth[m]'],c=flt[var],cmap = 'magma',)\n",
    "ax.invert_yaxis()\n",
    "ax.set_ylim([300,0])\n",
    "cb=plt.colorbar(sc)\n",
    "cb.set_label(var)\n",
    "sc.set_clim(vmin = 220, vmax = 280) # later make these adaptive to values in the depth range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed Layer Depth\n",
    "It would be helpful to know where the mixed layer is when we're thinking about surface ocean seasonality. Typically, mixed layer is calculated by looking at the density relative to the surface. As you move down the water column, the density increases and you can choose a threshold above which you are no longer in the mixed layer. This is typically 0.03 kg/m3 (https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2004JC002378). First let's look at density:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt['Sigma_theta[kg/m^3]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLD=np.empty(flt['Station'].max(), dtype=object)\n",
    "# need to finish this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next look at pCO2 over time\n",
    "var='pCO2_LIAR[µatm]'\n",
    "flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)\n",
    "fig = plt.figure(num=None, figsize=(10, 2), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc=ax.scatter(flt['date'],flt['Depth[m]'],c=flt[var],cmap = 'magma')\n",
    "ax.invert_yaxis()\n",
    "ax.set_ylim([300,0])\n",
    "cb=plt.colorbar(sc)\n",
    "cb.set_label(var)\n",
    "sc.set_clim(vmin = 350, vmax = 475) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next look at Nitrate over time\n",
    "var='Nitrate[µmol/kg]'\n",
    "fig = plt.figure(num=None, figsize=(10, 2), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc=ax.scatter(flt['date'],flt['Depth[m]'],c=flt[var],cmap = 'magma')\n",
    "ax.invert_yaxis()\n",
    "ax.set_ylim([300,0])\n",
    "cb=plt.colorbar(sc)\n",
    "cb.set_label(var)\n",
    "sc.set_clim(vmin = 0, vmax = 20) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var='Temperature[°C]'\n",
    "flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)\n",
    "var='Salinity[pss]'\n",
    "flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)\n",
    "\n",
    "sns.distplot(flt['Temperature[°C]'],kde='false')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x='Temperature[°C]',y='Salinity[pss]',data=flt,kind='hex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltsmall=flt[['Nitrate[µmol/kg]','Oxygen[µmol/kg]','pCO2_LIAR[µatm]','Temperature[°C]','Depth[m]']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltsmall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(fltsmall)\n",
    "# This will take some time. Notice the \"*\" that appears to the upper left while the cell runs\n",
    "# If something is taking longer to run than you think it should, that's called \"hanging\" and\n",
    "# It may be due to an error. You can quit that cell by going up to \"Kernel\" in the menu bar and \n",
    "# clicking \"interrupt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this code to subsample the larger dataframe to be used with seaborn grid plots\n",
    "# a=flt.pivot_table(index='Pressure[dbar]',columns='Station',values='Temperature[°C]')\n",
    "# a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regression plots\n",
    "# What is the relationsihp between TALK and S? Do you think that Alkalinity can be estimated from just salinity?\n",
    "sns.lmplot(x='Salinity[pss]',y='TALK_LIAR[µmol/kg]',data=flt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(x='Salinity[pss]',y='Nitrate[µmol/kg]',data=flt) #Seaborn linear model plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are these two different blobs? Plot a third variable as a color\n",
    "flt.plot.scatter(x='Salinity[pss]',y='DIC_LIAR[µmol/kg]',c='Pressure[dbar]',cmap='Purples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_by_station=flt.groupby('Station').mean() #This doesn't make much oceanographic sense,\n",
    "# I just wanted to share the groupby tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt_by_station"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
