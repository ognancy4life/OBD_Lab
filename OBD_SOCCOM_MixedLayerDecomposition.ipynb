{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ocean Biogeochemical Dynamics Lab, Spring 2021\n",
    "Doing simple seasonal decomposition of drivers of DIC and TA with SOCCOM floats by Nancy Williams\n",
    "\n",
    "This assumes you have already become familiar with `OBD_SOCCOM_L3.ipynb` and `OBD_SOCCOM_CO2SYS.ipynb` notebooks.\n",
    "\n",
    "SOCCOM website: https://soccom.princeton.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.path as mpath\n",
    "import seaborn as sns # this will change the look of pandas plots, too\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature\n",
    "import seawater\n",
    "import xarray as xr\n",
    "from PyCO2SYS.api import CO2SYS_wrap as co2sys\n",
    "# this forces matplotlib to print figures out here when you make plots\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = (15, 9)\n",
    "plt.rcParams['font.size'] = 18\n",
    "#plt.rcParams['lines.linewidth'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the directory where you want the figures to be saved\n",
    "output_dir = 'generated/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing the dataset\n",
    "We want to use Pandas' built-in read_csv function to import a single float data file into a pandas data frame called `flt`. Float 9254 is a good example float for this exercise, but you can pick any float from the snapshot. To pick another float you can go to the SOCCOM web page sensor status table http://soccom.ucsd.edu/floats/SOCCOM_sensor_stats.html and choose a float with lots of good data (i.e., more in the \"#g\" column than the \"#b\" columns for variables you're interested in analyzing. You can sort the columns on that webpage by clicking on the column header by which you wish to sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a float\n",
    "floatnum = '9254' \n",
    "floatpath = 'SOCCOM_LoResQC_LIAR_22Dec2020_odvtxt/' # This is the folder where all the float data live\n",
    "floatsuffix = 'SOOCNQC.TXT' # all of the Southern Ocean floats have the same suffix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change // comment symbols to #\n",
    "# input file\n",
    "fin = open(floatpath+floatnum+floatsuffix,'rt',encoding='UTF-8')\n",
    "\n",
    "# output file to which we will write the result\n",
    "fout = open('fltrem.txt','wt')\n",
    "\n",
    "# this is a for loop\n",
    "# for each line in the input file\n",
    "for line in fin:\n",
    "    # red and replace the string and write to the output file\n",
    "    fout.write(line.replace('//','#'))\n",
    "# close the files\n",
    "fin.close()\n",
    "fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt = pd.read_csv(\n",
    "    'fltrem.txt',\n",
    "    delimiter='\\t',\n",
    "    comment='#',\n",
    "    na_values=-1E10,\n",
    ")\n",
    "\n",
    "flt['date'] = pd.to_datetime(flt['mon/day/yr'] + ' ' + flt['hh:mm'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all Quality Flag columns and apply them to the preceeding columns\n",
    "from re import search\n",
    "for column in range(len(flt.columns)):\n",
    "    name=flt.columns[column]\n",
    "    if search('QF',name): # if the column is a QF column, apply it to the preceeding column, otherwise go on to next column\n",
    "        var=flt.columns[column-1]\n",
    "        flt[var] = np.where(flt.iloc[:,flt.columns.get_loc(var)+1] == 0,flt[var], np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mapping your data\n",
    "It's always a good idea to map your data and make sure it is where you think it is. Here we will use cartopy (basemap is deprecated).\n",
    "\n",
    "Since we're talking about the Southern Ocean and there are stark fronts, it's good to plot your data in relation to these fronts. The climatological locations of the fronts are available from Orsi et al. (1995) https://www.sciencedirect.com/science/article/pii/096706379500021W. Text files containing the locations of the fronts are located in the \"fronts\" folder.\n",
    "\n",
    ">Orsi, A. H., Whitworth, T. I., & Nowlin, W. D. J. (1995). On the meridional extent and fronts of the Antarctic Circumpolar Current. Deep Sea Research Part I. https://doi.org/10.1016/0967-0637(95)00021-W\n",
    "\n",
    "### Where is your float in relation to the fronts of the ACC?\n",
    "The following code imports the longitudes and latitudes of the five fronts. There are some '%' values in the files which creates breaks in the fronts. If we did not keep these breaks, the fronts would plot across continents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_front_csv(name):\n",
    "    \"\"\"read Orsi front csv file into pandas dataframe\"\"\"\n",
    "    return pd.read_csv(\n",
    "        f'fronts/{name}.txt', #fstrings\n",
    "        header=None,\n",
    "        sep='\\s+',\n",
    "        na_values='%',\n",
    "        names=['lon', 'lat'],\n",
    "    )\n",
    "\n",
    "stf = read_front_csv('stf')\n",
    "saf = read_front_csv('saf')\n",
    "pf = read_front_csv('pf')\n",
    "saccf = read_front_csv('saccf')\n",
    "sbdy = read_front_csv('sbdy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following is an example of a South Polar Stereographic map using Cartopy https://scitools.org.uk/cartopy/docs/latest/#. Polar stereographic maps are always a bit more complicated because you have to translate your coordinates to polar coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize =(6, 6))\n",
    "ax = plt.axes(projection=ccrs.SouthPolarStereo())\n",
    "ax.set_extent([-180,180,-90,-30], ccrs.PlateCarree())\n",
    "ax.add_feature(cartopy.feature.LAND)\n",
    "ax.add_feature(cartopy.feature.OCEAN)\n",
    "ax.gridlines()\n",
    "\n",
    "# Compute a circle in axes coordinates, which we can use as a boundary\n",
    "# for the map. We can pan/zoom as much as we like - the boundary will be\n",
    "# permanently circular.\n",
    "theta = np.linspace(0, 2*np.pi, 100)\n",
    "center, radius = [0.5, 0.5], 0.5\n",
    "verts = np.vstack([np.sin(theta), np.cos(theta)]).T\n",
    "circle = mpath.Path(verts * radius + center)\n",
    "\n",
    "ax.set_boundary(circle, transform = ax.transAxes)\n",
    "plt.plot(stf['lon'], stf['lat'], color='Red', transform=ccrs.PlateCarree())\n",
    "plt.plot(saf['lon'], saf['lat'], color='Orange', transform=ccrs.PlateCarree())\n",
    "plt.plot(pf['lon'], pf['lat'], color='Yellow', transform=ccrs.PlateCarree())\n",
    "plt.plot(saccf['lon'], saccf['lat'], color='Green', transform=ccrs.PlateCarree())\n",
    "plt.plot(sbdy['lon'], sbdy['lat'], color='Blue', transform=ccrs.PlateCarree())\n",
    "\n",
    "plt.scatter(flt['Lon [°E]'],flt['Lat [°N]'], color='Black', transform=ccrs.PlateCarree(), s=1)\n",
    "plt.savefig(output_dir + 'F' +floatnum + 'map.png') \n",
    "plt.savefig(output_dir + 'F' +floatnum + 'map.jpg') # Changing the suffix will change the format\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MLD for each station\n",
    "MLD = []\n",
    "for station in flt['Station'].unique():\n",
    "    surfacedens = flt['Sigma_theta[kg/m^3]'].loc[(flt['Station']==station)].min()\n",
    "    MLD.append(\n",
    "        [station,flt['date'].loc[(flt['Station']==station)&\n",
    "                                 (flt['Sigma_theta[kg/m^3]']-surfacedens>0.03)].min(),\n",
    "         flt['Depth[m]'].loc[(flt['Station']==station)&\n",
    "                             (flt['Sigma_theta[kg/m^3]']-surfacedens>0.03)].min(),\n",
    "         flt['Lon [°E]'].loc[(flt['Station']==station)].mean(),\n",
    "         flt['Lat [°N]'].loc[(flt['Station']==station)].mean()])\n",
    "\n",
    "# Take a look at MLD. First column is the Station, second column is datenum, second column is the MLD\n",
    "MLD = pd.DataFrame(data=MLD, columns=['Station', 'date', 'MLD','Lon [°E]','Lat [°N]'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do some CO2SYS calculations using PyCO2SYS\n",
    "This section uses PyCO2sys to do some carbonate system calculations using the float data. The float pH sensor measures pH with an uncertainty of about 0.01 (Williams et al., 2017; Johnson et al., 2017). We need a second variable in order to do CO2SYS calculations, and the easiest to estimate in this case is total alkalinity, or TA. The estimate for TA comes from an empirical algorithm called LIARv2. LIARv2 uses float-measured salinity, temperature, pressure, oxygen, and location along with existing nearby bottle measurements for alkalinity to estimate TA at the float's location with an uncertainty of about 6.5 umol/kg (Carter et al., 2018). \n",
    "\n",
    ">Williams, N. L., Juranek, L. W., Feely, R. A., Johnson, K. S., Sarmiento, J. L., Talley, L. D., et al. (2017). Calculating surface ocean pCO2 from biogeochemical Argo floats equipped with pH: An uncertainty analysis. Global Biogeochemical Cycles, 31(3), 591–604. https://doi.org/10.1002/2016GB005541\n",
    "\n",
    ">Johnson, K. S., Plant, J. N., Coletti, L. J., Jannasch, H. W., Sakamoto, C. M., Riser, S. C., et al. (2017). Biogeochemical sensor performance in the SOCCOM profiling float array. Journal of Geophysical Research: Oceans, 122(8), 6416–6436. https://doi.org/10.1002/2017JC012838\n",
    "\n",
    ">Carter, B. R., Feely, R. A., Williams, N. L., Dickson, A. G., Fong, M. B., & Takeshita, Y. (2018). Updated methods for global locally interpolated estimation of alkalinity, pH, and nitrate. Limnology and Oceanography: Methods, 16(2), 119–131. https://doi.org/10.1002/lom3.10232\n",
    "\n",
    "If you use PyCO2SYS in your own research, please cite: \n",
    "\n",
    ">Humphreys, M. P., Gregor, L., Pierrot, D., van Heuven, S. M. A. C., Lewis, E. R., and Wallace, D. W. R. (2020). PyCO2SYS: marine carbonate system calculations in Python. Zenodo. doi:10.5281/zenodo.3744275.\n",
    "\n",
    "As well as the original CO2SYS:\n",
    "\n",
    ">van Heuven, S., Pierrot, D., Rae, J. W. B., Lewis, E., and Wallace, D. W. R. (2011). CO2SYS v 1.1, MATLAB program developed for CO2 system calculations. ORNL/CDIAC-105b, Carbon Dioxide Information Analysis Center, Oak Ridge National Laboratory, U.S. Department of Energy, Oak Ridge, TN, USA. doi:10.3334/CDIAC/otg.CO2SYS_MATLAB_v1.1.\n",
    "\n",
    "More examples available at https://github.com/mvdh7/PyCO2SYS-examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, let's do an example to make sure we understand the various inputs and outputs:\n",
    "To do carbonate system calculations you need to have measured (or estimated) at least two of the measurable variables (DIC, TA, pCO2, pH).\n",
    "\n",
    "Below are two ways to call co2sys which are reminiscent of how it is used in MATLAB. You only have to enter the two carbonate system variables, and if you enter nothing else co2sys will assume \"standard\" conditions of S=35, T=25, and a default set of constants. A list of all possible inputs is available here: https://pyco2sys.readthedocs.io/en/latest/co2sys/#inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do an example\n",
    "# Call with defaults\n",
    "df1 = co2sys(dic=2103, alk=2360)\n",
    "\n",
    "# The above is equivalent to:\n",
    "df1 = co2sys(\n",
    "    dic=2103, alk=2360, pco2=None, fco2=None, pH=None,\n",
    "    carb=None, bicarb=None, co2aq=None,\n",
    "    temp_in=25, temp_out=25, pres_in=0, pres_out=0,\n",
    "    sal=35, si=0, po4=0, nh3=0, h2s=0,\n",
    "    K1K2_constants=4, KSO4_constants=1, KF_constant=1, pHscale_in=1,\n",
    "    buffers_mode=\"auto\", verbose=True\n",
    ")\n",
    "# You can see from the output below that this block of code runs twice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the output\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is one long row with 132 columns of both input and output similar to the excel version or the MATLAB version. A list of all outputs is avaiable here: https://pyco2sys.readthedocs.io/en/latest/co2sys/#outputs\n",
    "\n",
    "You can call a specific column with your result of interest. What is the saturation state of aragonite? Is this example above or below saturation (i.e., will aragonite shells tend to dissolve or be stable at these conditions?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['OmegaARout']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's use co2sys to calculate aragonite saturation state (OmegaAr) from the float data. We need to provide more information than in the simple example above, because the float is measuring at a range of temperature, salinity, and pressure conditions. These are called \"in situ\" conditions. For a float, we are interested in what's happening in situ, so both our input and output conditions will be the in situ conditions and they will be the same.\n",
    "\n",
    ">As a side note: you would do something different if you were measuring a water sample in the lab, and then you wish to back-calculate what your sample looked like at in situ conditions (i.e. wherever you sampled it from). In that case, your input conditions would be your lab conditions, and your output conditions would be the insitu conditions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = co2sys(\n",
    "    pH=flt['pHinsitu[Total]'], alk=flt['TALK_LIAR[µmol/kg]'],\n",
    "    temp_in=flt['Temperature[°C]'], temp_out=flt['Temperature[°C]'], \n",
    "    pres_in=flt['Pressure[dbar]'], pres_out=flt['Pressure[dbar]'],\n",
    "    sal=flt['Salinity[pss]'], si=0, po4=0, nh3=0, h2s=0,\n",
    "    K1K2_constants=10, KSO4_constants=1, KF_constant=1, pHscale_in=1,\n",
    "    buffers_mode=\"auto\", verbose=True,\n",
    ")\n",
    "\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the newly-calculated OmegaAr to the flt dataframe\n",
    "flt['OmegaAr'] = df1['OmegaARout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the saturation state of aragonite (Omega_Ar) you calculated\n",
    "# First, set the depth to which you wish to plot and keep it the same for subsequent plots\n",
    "depth = MLD['MLD'].max() + 50 #plot to depth of mixed layer plus some number of m\n",
    "\n",
    "var ='OmegaAr'\n",
    "fig = plt.figure(num=None, figsize=(16,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc = ax.scatter(flt['date'], flt['Depth[m]'], c=flt[var], cmap = 'RdBu')\n",
    "ax.plot(MLD['date'], MLD['MLD'], c='magenta')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Float ' + floatnum)\n",
    "ax.set_ylim([depth, 0])\n",
    "cb=plt.colorbar(sc)\n",
    "cb.set_label(var)\n",
    "# automatically adjusts the colorbar based on the range of values youre plotting\n",
    "sc.set_clim(vmin = flt[var].loc[(flt['Depth[m]']<depth)].min(), \n",
    "            vmax = flt[var].loc[(flt['Depth[m]']<depth)].max()) \n",
    "fig.savefig(output_dir + 'F' + floatnum + var[0:3] + 'section.png', dpi= 200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the depth of the Aragonite Saturation Horizon\n",
    "It is useful to know the depth at which aragonite transitions from being stable to unstable. In some parts of the ocean, this depth is very deep, but in the Southern Ocean it can be near the surface. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate zsatarag for each station\n",
    "zsatarag=[]\n",
    "for station in flt['Station'].unique():\n",
    "    zsatarag.append(\n",
    "        [station,flt['date'].loc[(flt['Station']==station)&(flt['OmegaAr']<1)].min(),\n",
    "         flt['Depth[m]'].loc[(flt['Station']==station)&(flt['OmegaAr']<1)].min(),\n",
    "         flt['Lon [°E]'].loc[(flt['Station']==station)].mean(),\n",
    "         flt['Lat [°N]'].loc[(flt['Station']==station)].mean()]\n",
    "    )\n",
    "\n",
    "# Take a look at zsatarag. First column is the Station, second column is datenum, second column is the zsatarag\n",
    "zsatarag = pd.DataFrame(data=zsatarag, columns=['Station', 'date', 'zsatarag','Lon [°E]','Lat [°N]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the zsatarag and saturation state of aragonite (Omega_Ar) you calculated\n",
    "# First, set the depth to which you wish to plot and keep it the same for subsequent plots\n",
    "depth = zsatarag['zsatarag'].max() + 50 #plot to depth of mixed layer plus some number of m\n",
    "\n",
    "var ='OmegaAr'\n",
    "fig = plt.figure(num=None, figsize=(16,3), dpi=80, facecolor='w', edgecolor='k')\n",
    "ax = fig.add_axes([0.1, 0.1, .8, .8])\n",
    "sc=ax.scatter(flt['date'], flt['Depth[m]'], c=flt[var], cmap = 'RdBu')\n",
    "ax.plot(MLD['date'], MLD['MLD'], c='magenta')\n",
    "ax.plot(zsatarag['date'], zsatarag['zsatarag'], c='black')\n",
    "ax.invert_yaxis()\n",
    "ax.set_title('Float ' + floatnum)\n",
    "ax.set_ylim([depth, 0])\n",
    "cb = plt.colorbar(sc)\n",
    "cb.set_label(var)\n",
    "# automatically adjusts the colorbar based on the range of values youre plotting\n",
    "sc.set_clim(vmin=flt[var].loc[(flt['Depth[m]']<depth)].min(), \n",
    "            vmax=flt[var].loc[(flt['Depth[m]']<depth)].max()) \n",
    "fig.savefig(output_dir + 'F' + floatnum + var[0:3] + 'zsataragsection.png', dpi=200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where in the water column is the aragonite saturation horizon? What does this mean for calcifying organisms in the area? Do you think this region will be vulnerable to continued ocean acidification?\n",
    "\n",
    "Seasonality is also important. What is the seasonality in aragonite saturation in the mixed layer? Negative impacts to organisms have been shown to occur even before aragonite saturation reaches 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a time series plot of average mixed layer observations\n",
    "Here we first pull only the data from the mixed layer and put into a separate dataframe called `fltSurf`. We then use the pandas groupby function to group and average the mixed layer data by station.\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltSurf = pd.DataFrame()\n",
    "for station in MLD['Station']:\n",
    "    stationMLD = MLD.MLD[MLD.Station==station].values[0]\n",
    "    mask = (flt['Station']==station) & (flt['Pressure[dbar]']<stationMLD)\n",
    "    fltSurf = fltSurf.append(flt[mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltSurfByStn = fltSurf.groupby('Station').mean()\n",
    "fltSurfByStn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Groupby doesn't work on datetime column so it was dropped. We need to make a datetime array to be used with plotting\n",
    "fltdates = []\n",
    "for station in flt['Station'].unique():\n",
    "    fltdates.append([flt['date'].loc[(flt['Station']==station)].min()])\n",
    "len(fltdates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unfortunately, sometimes the fltdates is 1 row longer than the groupby file. \n",
    "# Not sure how/why this happened but for now, we will just assume that \n",
    "# there is an extra date somewhere and drop the final date.\n",
    "# Need to fix this later. It might lead to a 10-day error in the dates\n",
    "if len(fltdates)>len(fltSurfByStn):\n",
    "    fltdates.pop(len(fltdates)-len(fltSurfByStn))# pop \"pops off\" the last value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a big plot with subplots\n",
    "fig,axes = plt.subplots(nrows = 7, ncols = 1,figsize=(15,25))\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "var='Temperature[°C]'\n",
    "axes[0].plot(fltdates,fltSurfByStn[var])\n",
    "axes[0].set_ylabel(var)\n",
    "axes[0].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[0].xaxis.set_major_locator(years)\n",
    "axes[0].xaxis.set_major_formatter(years_fmt)\n",
    "axes[0].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='Salinity[pss]'\n",
    "axes[1].plot(fltdates,fltSurfByStn[var])\n",
    "axes[1].set_ylabel(var)\n",
    "axes[1].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[1].xaxis.set_major_locator(years)\n",
    "axes[1].xaxis.set_major_formatter(years_fmt)\n",
    "axes[1].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='OmegaAr'\n",
    "axes[2].plot(fltdates,fltSurfByStn[var])\n",
    "axes[2].set_ylabel(var)\n",
    "axes[2].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[2].xaxis.set_major_locator(years)\n",
    "axes[2].xaxis.set_major_formatter(years_fmt)\n",
    "axes[2].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='TALK_LIAR[µmol/kg]'\n",
    "axes[3].plot(fltdates,fltSurfByStn[var])\n",
    "axes[3].set_ylabel(var)\n",
    "axes[3].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[3].xaxis.set_major_locator(years)\n",
    "axes[3].xaxis.set_major_formatter(years_fmt)\n",
    "axes[3].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='pHinsitu[Total]'\n",
    "axes[4].plot(fltdates,fltSurfByStn[var])\n",
    "axes[4].set_ylabel(var)\n",
    "axes[4].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[4].xaxis.set_major_locator(years)\n",
    "axes[4].xaxis.set_major_formatter(years_fmt)\n",
    "axes[4].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='pCO2_LIAR[µatm]'\n",
    "axes[5].plot(fltdates,fltSurfByStn[var])\n",
    "axes[5].set_ylabel(var)\n",
    "axes[5].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[5].xaxis.set_major_locator(years)\n",
    "axes[5].xaxis.set_major_formatter(years_fmt)\n",
    "axes[5].xaxis.set_minor_locator(months)\n",
    "\n",
    "var='MLD'\n",
    "axes[6].plot(MLD['date'],MLD['MLD'])\n",
    "axes[6].set_ylabel(var)\n",
    "axes[6].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[6].xaxis.set_major_locator(years)\n",
    "axes[6].xaxis.set_major_formatter(years_fmt)\n",
    "axes[6].xaxis.set_minor_locator(months)\n",
    "\n",
    "axes[0].set_title('Float ' + floatnum)\n",
    "fig.savefig(output_dir + 'F' + floatnum + 'CO2SYS.png', dpi = 200, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What will the aragonite saturation look like in 50 years?\n",
    "How would you go about answering this question using CO2SYS? Some useful info is compiled in Table 5 of Williams et al. (2015):\n",
    ">Williams, N. L., Feely, R. A., Sabine, C. L., Dickson, A. G., Swift, J. H., Talley, L. D., & Russell, J. L. (2015). Quantifying anthropogenic carbon inventory changes in the Pacific sector of the Southern Ocean. Marine Chemistry, 174, 147–160. https://doi.org/10.1016/j.marchem.2015.06.015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image('Williamsetal2015SouthernOceanOArates.png', width=800)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above table gives ocean acidification rates for the Southern Ocean as well as other ocean regions. The OA rate for pH for the Southern Ocean is about -0.002/year. Just for demonstration, we will subtract 50 * 0.002 from our observed surface pH in order to get the future conditions. \n",
    "\n",
    "As a side note: It is best to discuss and calculate OA changes in terms of [H+] and not pH because pH is a log scale and OA rates in terms of pH are therefore not linear. It is the [H+] that is changing! See technical note:\n",
    ">Fassbender, A., Orr, J., & Dickson, A. (2020). Technical note: Interpreting pH changes. Biogeosciences Discussions, 10(2), 1–14. https://doi.org/10.5194/bg-2020-348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new variable called pH2070 to represent the pH in 50 years\n",
    "fltSurfByStn['pH2070'] = fltSurfByStn['pHinsitu[Total]'] - 50 * (0.002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run CO2SYS with your future pH and the same total alkalinity\n",
    "df2 = co2sys(\n",
    "    pH=fltSurfByStn['pH2070'], alk=fltSurfByStn['TALK_LIAR[µmol/kg]'],\n",
    "    temp_in=fltSurfByStn['Temperature[°C]'], temp_out=fltSurfByStn['Temperature[°C]'], \n",
    "    pres_in=fltSurfByStn['Pressure[dbar]'], pres_out=fltSurfByStn['Pressure[dbar]'],\n",
    "    sal=fltSurfByStn['Salinity[pss]'], si=0, po4=0, nh3=0, h2s=0,\n",
    "    K1K2_constants=10, KSO4_constants=1, KF_constant=1, pHscale_in=1,\n",
    "    buffers_mode=\"auto\", verbose=True)\n",
    "df2\n",
    "\n",
    "# Add the newly-calculated OmegaAr2070 to the fltSurfByStn dataframe\n",
    "fltSurfByStn['OmegaAr2070'] = df2['OmegaARout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting OmegaAr and OmegaAr2070 on one plot\n",
    "fig, ax = plt.subplots()\n",
    "var='OmegaAr'\n",
    "var2='OmegaAr2070'\n",
    "im = ax.plot(fltdates,fltSurfByStn[var],label=var)\n",
    "im2 = ax.plot(fltdates,fltSurfByStn[var2],label=var2)\n",
    "ax.set_ylabel(var) # fontsize=fs)\n",
    "ax.legend()\n",
    "plt.title('Float ' + floatnum + ' Surface in 50 years')\n",
    "fig.savefig(output_dir + 'F' + floatnum + 'CO2SYS2070.png', dpi=200, bbox_inches='tight')\n",
    "plt.show() # displays plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed layer decomposition\n",
    "Next, we will do a simple decomposition of the drivers of DIC and TA over the annual cycle. This simple decomposition does not account for the differences between processes which might add/subtract DIC and TA from the mixed layer through physical processes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltSurfByStn['dS'] = fltSurfByStn['Salinity[pss]'].diff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Deltas = fltSurfByStn.diff()\n",
    "Deltas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now what if we want to get really fancy and add the suppy of \"things\" from below (entrainment)?\n",
    "# First let's calculate the sub-mixed layer values\n",
    "fltSubMLD = pd.DataFrame()\n",
    "for station in MLD['Station']:\n",
    "    stationMLD = MLD.MLD[MLD.Station==station].values[0]\n",
    "    mask = (flt['Station']==station) & (flt['Pressure[dbar]']>stationMLD+10) & (flt['Pressure[dbar]']<stationMLD+100)\n",
    "    fltSubMLD = fltSubMLD.append(flt[mask])\n",
    "fltSubMLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fltSubMLDByStn = fltSubMLD.groupby('Station').mean()\n",
    "fltSubMLDByStn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# When the mixed layer is deepening (dMLD is positive) calculate dN_dMLD\n",
    "# NEED TO FIX THIS SO THAT THE INDICES FOR d_dMLD are the stations.\n",
    "dN_dMLD = pd.DataFrame()\n",
    "dTA_dMLD = pd.DataFrame()\n",
    "dDIC_dMLD = pd.DataFrame()\n",
    "for station in MLD['Station'].unique():\n",
    "    if station == 1:\n",
    "        #dN_dMLD = dN_dMLD.append([np.nan], ignore_index=True)\n",
    "        #dTA_dMLD = dTA_dMLD.append([np.nan], ignore_index=True)\n",
    "        #dDIC_dMLD = dDIC_dMLD.append([np.nan], ignore_index=True)\n",
    "        continue\n",
    "    dMLD = MLD.MLD[MLD.Station==station].values[0] - MLD.MLD[MLD.Station==station-1].values[0]\n",
    "    if (station > 1) & (dMLD > 0):\n",
    "        dN_dMLD = dN_dMLD.append([\n",
    "            (fltSubMLDByStn['Nitrate[µmol/kg]'].loc[station] -\n",
    "            fltSurfByStn['Nitrate[µmol/kg]'].loc[station]) * \n",
    "            dMLD / MLD.MLD[MLD.Station==station].values[0]], ignore_index=True)\n",
    "        dTA_dMLD = dTA_dMLD.append([\n",
    "            (fltSubMLDByStn['TALK_LIAR[µmol/kg]'].loc[station] -\n",
    "            fltSurfByStn['TALK_LIAR[µmol/kg]'].loc[station]) * \n",
    "            dMLD / MLD.MLD[MLD.Station==station].values[0]], ignore_index=True)\n",
    "        dDIC_dMLD = dDIC_dMLD.append([\n",
    "            (fltSubMLDByStn['DIC_LIAR[µmol/kg]'].loc[station] -\n",
    "            fltSurfByStn['DIC_LIAR[µmol/kg]'].loc[station]) * \n",
    "            dMLD / MLD.MLD[MLD.Station==station].values[0]], ignore_index=True)\n",
    "    else:\n",
    "        dN_dMLD = dN_dMLD.append([0], ignore_index=True)\n",
    "        dTA_dMLD = dN_dMLD.append([0], ignore_index=True)\n",
    "        dDIC_dMLD = dN_dMLD.append([0], ignore_index=True)\n",
    "        \n",
    "dN_dMLD = dN_dMLD.iloc[1:,0]\n",
    "dTA_dMLD = dTA_dMLD.iloc[1:,0]\n",
    "dDIC_dMLD = dDIC_dMLD.iloc[1:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dDIC_dS = Deltas['Salinity[pss]'] * fltSurfByStn['DIC_LIAR[µmol/kg]'].iloc[0] / fltSurfByStn['Salinity[pss]'].iloc[0]\n",
    "dTA_dS = Deltas['Salinity[pss]'] * fltSurfByStn['TALK_LIAR[µmol/kg]'].iloc[0] / fltSurfByStn['Salinity[pss]'].iloc[0]\n",
    "dN_dS = Deltas['Salinity[pss]'] * fltSurfByStn['Nitrate[µmol/kg]'].iloc[0] / fltSurfByStn['Salinity[pss]'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dN_NCM = Deltas['Nitrate[µmol/kg]'] - dN_dS #- dN_dMLD # Station indexing is missing/wrong for dN_dMLD\n",
    "dDIC_NCM = dN_NCM * 117 / 16\n",
    "dTA_NCM = dN_NCM * -16 / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dTA_CaCO3 = Deltas['TALK_LIAR[µmol/kg]'] - dTA_dS - dTA_NCM #- dTA_dMLD\n",
    "dDIC_CaCO3 = dTA_CaCO3 * 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dDIC_resid = Deltas['DIC_LIAR[µmol/kg]'] - dDIC_dS - dDIC_NCM - dDIC_CaCO3 #- dDIC_dMLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a big plot with subplots\n",
    "fig,axes = plt.subplots(nrows = 3, ncols = 1,figsize=(15,15))\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "years = mdates.YearLocator()   # every year\n",
    "months = mdates.MonthLocator()  # every month\n",
    "years_fmt = mdates.DateFormatter('%Y')\n",
    "\n",
    "var='DIC_LIAR[µmol/kg]'\n",
    "axes[0].plot(fltdates,Deltas[var].cumsum(), label='Observed', c='black', linewidth=3)\n",
    "axes[0].set_ylabel('Change in ' + var[:3] + ' ' + var [-9:])\n",
    "axes[0].plot(fltdates,dDIC_dS.cumsum(), label='evap/precip', c='deeppink', linewidth=2)\n",
    "#axes[0].plot(fltdates,dDIC_dMLD.cumsum(), label='entrainment', c='forestgreen', linewidth=2)\n",
    "axes[0].plot(fltdates,dDIC_NCM.cumsum(), label='net community metabolism', c='cyan', linewidth=2)\n",
    "axes[0].plot(fltdates,dDIC_CaCO3.cumsum(), label='calcification/dissolution', c='mediumorchid', linewidth=2)\n",
    "axes[0].plot(fltdates,dDIC_resid.cumsum(), label='residual (gas exchange + physical)', c='grey', linewidth=2)\n",
    "axes[0].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[0].xaxis.set_major_locator(years)\n",
    "axes[0].xaxis.set_major_formatter(years_fmt)\n",
    "axes[0].xaxis.set_minor_locator(months)\n",
    "axes[0].legend()\n",
    "\n",
    "var='TALK_LIAR[µmol/kg]'\n",
    "axes[1].plot(fltdates,Deltas[var].cumsum(), label='Observed', c='black', linewidth=3)\n",
    "axes[1].set_ylabel('Change in ' + var[:4] + ' ' + var [-9:])\n",
    "axes[1].plot(fltdates,dTA_dS.cumsum(), label='evap/precip', c='deeppink', linewidth=2)\n",
    "#axes[1].plot(fltdates,dTA_dMLD.cumsum(), label='entrainment', c='forestgreen', linewidth=2)\n",
    "axes[1].plot(fltdates,dTA_NCM.cumsum(), label='net community metabolism', c='cyan', linewidth=2)\n",
    "axes[1].plot(fltdates,dTA_CaCO3.cumsum(), label='calcification/dissolution', c='mediumorchid', linewidth=2)\n",
    "axes[1].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[1].xaxis.set_major_locator(years)\n",
    "axes[1].xaxis.set_major_formatter(years_fmt)\n",
    "axes[1].xaxis.set_minor_locator(months)\n",
    "axes[1].legend()\n",
    "\n",
    "var = 'Nitrate[µmol/kg]'\n",
    "axes[2].plot(fltdates,Deltas[var].cumsum(), label='Observed', c='black', linewidth=3)\n",
    "axes[2].set_ylabel('Change in ' + var[:4] + ' ' + var [-9:])\n",
    "axes[2].plot(fltdates,dN_dS.cumsum(), label='evap/precip', c='deeppink', linewidth=2)\n",
    "#axes[3].plot(fltdates,dN_dMLD.cumsum(), label='entrainment', c='forestgreen', linewidth=2)\n",
    "axes[2].plot(fltdates,dN_NCM.cumsum(), label='net community metabolism', c='cyan', linewidth=2)\n",
    "axes[2].set_xlim(fltdates[0],fltdates[-1])\n",
    "axes[2].xaxis.set_major_locator(years)\n",
    "axes[2].xaxis.set_major_formatter(years_fmt)\n",
    "axes[2].xaxis.set_minor_locator(months)\n",
    "axes[2].legend()\n",
    "\n",
    "axes[0].set_title('Float ' + floatnum + ' Mixed Layer Decomposition')\n",
    "fig.savefig(output_dir + 'F' + floatnum + 'MLDecomp.png', dpi = 200, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
